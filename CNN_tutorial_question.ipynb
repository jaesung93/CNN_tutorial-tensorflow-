{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "CNN_tutorial_final.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true,
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jaesung93/CNN_tutorial-tensorflow-/blob/master/CNN_tutorial_question.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uI4av3fij5uL",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "print(\"Tutorial Question 10/21\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rdg_sYbkkGR3",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Load dataset\n",
    "cifar10 = keras.datasets.cifar10\n",
    "\n",
    "print(cifar10)\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "x_a7kRBskXeP",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "class_names =  ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer',\n",
    "               'Dog', 'Frog', 'Horse', 'Ship', 'Truck']"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XHj63oapkds7",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Cifar10 example\n",
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uW-yYgB3kp9e",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lbWJ4BT8k216",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Show images and labels\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i][0]])\n",
    "plt.show()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7XRClHKryg_L",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# For logging\n",
    "class CollectBatchStats(tf.keras.callbacks.Callback):\n",
    "  def __init__(self):\n",
    "    self.batch_losses = []\n",
    "    self.batch_acc = []\n",
    "    self.epoch_val_acc = []\n",
    "    \n",
    "  def on_batch_end(self, batch, logs=None):\n",
    "    self.batch_losses.append(logs['loss'])\n",
    "    self.batch_acc.append(logs['accuracy'])\n",
    "   \n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    self.epoch_val_acc.append(logs['val_accuracy'])\n",
    "    \n",
    "    \n",
    "def scheduler(epoch, lr):\n",
    "  \"\"\"Helper function to retrieve the scheduled learning rate based on epoch.\"\"\"\n",
    "  if epoch == 40 or epoch ==60 : \n",
    "    lr = lr  * 0.1\n",
    "  else:\n",
    "    lr = lr\n",
    "  return lr"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FExbAhlM7hJP",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://ibb.co/6Y82nPk\"><img src=\"https://i.ibb.co/cJwPgFj/fc.png\" alt=\"fc\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MQPjiUknJiKQ",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Fully connected network without ReLU\n",
    "fc_model_without_relu = keras.Sequential([\n",
    "    # Implement layers here\n",
    "])\n",
    "fc_model_without_relu.summary()\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "f5X4kkJ4JkAY",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Compile fully connected network without ReLU\n",
    "fc_model_without_relu.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                 loss='sparse_categorical_crossentropy',\n",
    "                 metrics=['accuracy']\n",
    ")"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7zEluS-MJl34",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Train fully connected network without ReLU\n",
    "fc_without_relu_batch_stats = CollectBatchStats()\n",
    "\n",
    "fc_model_without_relu.fit(train_images, train_labels,\n",
    "             batch_size=128,\n",
    "             epochs=70,\n",
    "             callbacks=[fc_without_relu_batch_stats, tf.keras.callbacks.LearningRateScheduler(scheduler)],\n",
    "             validation_data=(test_images, test_labels))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WSdwA3UIlzuQ",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Fully connected network\n",
    "fc_model = keras.Sequential([\n",
    "    # Implement layers here\n",
    "])\n",
    "fc_model.summary()\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-dat9vsevVuH",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Compile fully connected network\n",
    "fc_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                 loss='sparse_categorical_crossentropy',\n",
    "                 metrics=['accuracy']\n",
    ")"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DluWFOUtvx40",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Train fully connected network\n",
    "fc_batch_stats = CollectBatchStats()\n",
    "\n",
    "fc_model.fit(train_images, train_labels,\n",
    "             batch_size=128,\n",
    "             epochs=70,\n",
    "             callbacks=[fc_batch_stats, tf.keras.callbacks.LearningRateScheduler(scheduler)],\n",
    "             validation_data=(test_images, test_labels))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sRadrwnLxk7X",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# show train losses, train accuracy, test accuracy\n",
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,2])\n",
    "plt.plot(fc_batch_stats.batch_losses)\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Training Accuracy\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(fc_batch_stats.batch_acc)\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(fc_batch_stats.epoch_val_acc)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFg2-MrR8JrD",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://ibb.co/ZdYWYxN\"><img src=\"https://i.ibb.co/Tcbmbtr/cnn.png\" alt=\"cnn\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QJhV-cI4v3b3",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Convolutional neural network\n",
    "cnn_model = keras.Sequential([\n",
    "    #Implement CNN layers here\n",
    "])\n",
    "cnn_model.summary()\n",
    "\n",
    "# Compile CNN model\n",
    "cnn_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "cnn_batch_stats = CollectBatchStats()\n",
    "\n",
    "# Train CNN model\n",
    "cnn_model.fit(train_images, train_labels,\n",
    "              batch_size=128,\n",
    "              epochs=70,\n",
    "              callbacks=[cnn_batch_stats, tf.keras.callbacks.LearningRateScheduler(scheduler)],\n",
    "              validation_data=(test_images, test_labels))\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,2])\n",
    "plt.plot(cnn_batch_stats.batch_losses)\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Train Accuracy\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(cnn_batch_stats.batch_acc)\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(cnn_batch_stats.epoch_val_acc)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2T7-NC2O2n9B",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Compare fully-connected network and CNN network\n",
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,2])\n",
    "plt.plot(fc_batch_stats.batch_losses, label='fc')\n",
    "plt.plot(cnn_batch_stats.batch_losses, label='cnn')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Training Accuracy\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(fc_batch_stats.batch_acc, label='fc')\n",
    "plt.plot(cnn_batch_stats.batch_acc, label='cnn')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(fc_batch_stats.epoch_val_acc, label='fc')\n",
    "plt.plot(cnn_batch_stats.epoch_val_acc, label='cnn')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "fc_test_loss, fc_test_acc = fc_model.evaluate(test_images, test_labels)\n",
    "cnn_test_loss, cnn_test_acc = cnn_model.evaluate(test_images, test_labels)\n",
    "\n",
    "print('fc test accuracy : ' + str(fc_test_acc))\n",
    "print('cnn test accuracy : ' + str(cnn_test_acc))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDIvE3T98Tvd",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://ibb.co/3fw8kGR\"><img src=\"https://i.ibb.co/yhDMVG4/vgg.png\" alt=\"vgg\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Jr_jUsYJAy22",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# VGG network\n",
    "vgg_model = keras.Sequential([\n",
    "    # Implement VGG network here\n",
    "])\n",
    "vgg_model.summary()\n",
    "\n",
    "vgg_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "vgg_batch_stats = CollectBatchStats()\n",
    "\n",
    "vgg_model.fit(train_images, train_labels,\n",
    "              batch_size=128,\n",
    "              epochs=70,\n",
    "              callbacks=[vgg_batch_stats, tf.keras.callbacks.LearningRateScheduler(scheduler)],\n",
    "              validation_data=(test_images, test_labels))\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,2])\n",
    "plt.plot(vgg_batch_stats.batch_losses)\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Train Accuracy\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(vgg_batch_stats.batch_acc)\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(vgg_batch_stats.epoch_val_acc)\n",
    "\n",
    "\n",
    "vgg_test_loss, vgg_test_acc = vgg_model.evaluate(test_images, test_labels)\n",
    "print('VGG test accuracy : ' + str(vgg_test_acc))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WCbpCzs5Dezi",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Compare simple CNN network and VGG network\n",
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,2])\n",
    "plt.plot(cnn_batch_stats.batch_losses, label='simple cnn')\n",
    "plt.plot(vgg_batch_stats.batch_losses, label='vgg')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Training Accuracy\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(cnn_batch_stats.batch_acc, label='simple cnn')\n",
    "plt.plot(vgg_batch_stats.batch_acc, label='vgg')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(cnn_batch_stats.epoch_val_acc, label='simple cnn')\n",
    "plt.plot(vgg_batch_stats.epoch_val_acc, label='vgg')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "cnn_test_loss, cnn_test_acc = cnn_model.evaluate(test_images, test_labels)\n",
    "vgg_test_loss, vgg_test_acc = vgg_model.evaluate(test_images, test_labels)\n",
    "\n",
    "print('simple cnn test accuracy : ' + str(cnn_test_acc))\n",
    "print('vgg test accuracy : ' + str(vgg_test_acc))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FanhtGFF8XRk",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://ibb.co/YBT4Bx3\"><img src=\"https://i.ibb.co/4RgwRH7/resnet.png\" alt=\"resnet\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "g_UOv4dmFAgk",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Residual network\n",
    "\n",
    "# Implement residual network here\n",
    "\n",
    "resnet_model = keras.models.Model(input, output)\n",
    "resnet_model.summary()\n",
    "\n",
    "resnet_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "resnet_batch_stats = CollectBatchStats()\n",
    "\n",
    "resnet_model.fit(train_images, train_labels,\n",
    "              batch_size=128,\n",
    "              epochs=70,\n",
    "              callbacks=[resnet_batch_stats, tf.keras.callbacks.LearningRateScheduler(scheduler)],\n",
    "              validation_data=(test_images, test_labels))\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,2])\n",
    "plt.plot(resnet_batch_stats.batch_losses)\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Train Accuracy\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(resnet_batch_stats.batch_acc)\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(resnet_batch_stats.epoch_val_acc)\n",
    "\n",
    "resnet_test_loss, resnet_test_acc = resnet_model.evaluate(test_images, test_labels)\n",
    "print('Resnet test accuracy : ' + str(resnet_test_acc))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EeiSE5xFD37z",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Compare VGG network and Residual network\n",
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,2])\n",
    "plt.plot(vgg_batch_stats.batch_losses, label='vgg')\n",
    "plt.plot(resnet_batch_stats.batch_losses, label='resnet')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Training Accuracy\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(vgg_batch_stats.batch_acc, label='vgg')\n",
    "plt.plot(resnet_batch_stats.batch_acc, label='resnet')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(vgg_batch_stats.epoch_val_acc, label='vgg')\n",
    "plt.plot(resnet_batch_stats.epoch_val_acc, label='resnet')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "vgg_test_loss, vgg_test_acc = vgg_model.evaluate(test_images, test_labels)\n",
    "resnet_test_loss, resnet_test_acc = resnet_model.evaluate(test_images, test_labels)\n",
    "\n",
    "print('vgg test accuracy : ' + str(vgg_test_acc))\n",
    "print('resnet test accuracy : ' + str(resnet_test_acc))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "D5my917H8SJE",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# VGG network very deep\n",
    "vgg_very_deep_model = keras.Sequential([\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same', input_shape=(32, 32, 3)),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
    "    keras.layers.ReLU(),\n",
    "    \n",
    "    keras.layers.MaxPool2D(2),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
    "    keras.layers.ReLU(),\n",
    "    \n",
    "    keras.layers.MaxPool2D(2),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
    "    keras.layers.ReLU(),\n",
    "\n",
    "    keras.layers.AveragePooling2D(pool_size=(8, 8)),\n",
    "\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "vgg_very_deep_model.summary()\n",
    "\n",
    "vgg_very_deep_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "vgg_very_deep_batch_stats = CollectBatchStats()\n",
    "\n",
    "vgg_very_deep_model.fit(train_images, train_labels,\n",
    "              batch_size=128,\n",
    "              epochs=70,\n",
    "              callbacks=[vgg_very_deep_batch_stats, tf.keras.callbacks.LearningRateScheduler(scheduler)],\n",
    "              validation_data=(test_images, test_labels))\n",
    "\n",
    "# Residual network very deep\n",
    "input = keras.layers.Input(shape=(32, 32, 3))\n",
    "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(input)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "skip = x\n",
    "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Add()([x, skip])\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "skip = x\n",
    "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Add()([x, skip])\n",
    "x = keras.layers.ReLU()(x)\n",
    "\n",
    "x = keras.layers.MaxPool2D(2)(x)\n",
    "\n",
    "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "skip = x\n",
    "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Add()([x, skip])\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "skip = x\n",
    "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Add()([x, skip])\n",
    "x = keras.layers.ReLU()(x)\n",
    "\n",
    "x = keras.layers.MaxPool2D(2)(x)\n",
    "\n",
    "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "skip = x\n",
    "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Add()([x, skip])\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "skip = x\n",
    "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Add()([x, skip])\n",
    "x = keras.layers.ReLU()(x)\n",
    "\n",
    "x = keras.layers.AveragePooling2D(pool_size=(8, 8))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "\n",
    "output = keras.layers.Dense(10, activation=tf.nn.softmax)(x)\n",
    "\n",
    "resnet_very_deep_model = keras.models.Model(input, output)\n",
    "resnet_very_deep_model.summary()\n",
    "\n",
    "resnet_very_deep_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "resnet_very_deep_batch_stats = CollectBatchStats()\n",
    "\n",
    "resnet_very_deep_model.fit(train_images, train_labels,\n",
    "              batch_size=128,\n",
    "              epochs=70,\n",
    "              callbacks=[resnet_very_deep_batch_stats, tf.keras.callbacks.LearningRateScheduler(scheduler)],\n",
    "              validation_data=(test_images, test_labels))\n",
    "\n",
    "# Compare VGG very deep network and Residual very deep network\n",
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,2])\n",
    "plt.plot(vgg_very_deep_batch_stats.batch_losses, label='vgg')\n",
    "plt.plot(resnet_very_deep_batch_stats.batch_losses, label='resnet')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Training Accuracy\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(vgg_very_deep_batch_stats.batch_acc, label='vgg')\n",
    "plt.plot(resnet_very_deep_batch_stats.batch_acc, label='resnet')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(vgg_very_deep_batch_stats.epoch_val_acc, label='vgg')\n",
    "plt.plot(resnet_very_deep_batch_stats.epoch_val_acc, label='resnet')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "vgg_very_deep_test_loss, vgg_very_deep_test_acc = vgg_very_deep_model.evaluate(test_images, test_labels)\n",
    "resnet_very_deep_test_loss, resnet_very_deep_test_acc = resnet_very_deep_model.evaluate(test_images, test_labels)\n",
    "\n",
    "print('vgg very deep test accuracy : ' + str(vgg_very_deep_test_acc))\n",
    "print('resnet very deep test accuracy : ' + str(resnet_very_deep_test_acc))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CizGpPUUximg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Residual network with weight decay\n",
    "input = keras.layers.Input(shape=(32, 32, 3))\n",
    "x = keras.layers.Conv2D(32, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(input)\n",
    "x = keras.layers.ReLU()(x)\n",
    "skip=x\n",
    "x = keras.layers.Conv2D(32, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Conv2D(32, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "x = keras.layers.Add()([x, skip])\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.MaxPool2D(2)(x)\n",
    "x = keras.layers.Conv2D(64, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "skip = x\n",
    "x = keras.layers.Conv2D(64, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Conv2D(64, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "x = keras.layers.Add()([x, skip])\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.MaxPool2D(2)(x)\n",
    "x = keras.layers.Conv2D(128, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "skip = x\n",
    "x = keras.layers.Conv2D(128, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Conv2D(128, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "x = keras.layers.Add()([x, skip])\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.AveragePooling2D(pool_size=(8, 8))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "output = keras.layers.Dense(10, activation=tf.nn.softmax, kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "\n",
    "resnet_with_weight_decay_model = keras.models.Model(input, output)\n",
    "resnet_with_weight_decay_model.summary()\n",
    "\n",
    "resnet_with_weight_decay_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "resnet_with_weight_decay_batch_stats = CollectBatchStats()\n",
    "\n",
    "resnet_with_weight_decay_model.fit(train_images, train_labels,\n",
    "              batch_size=128,\n",
    "              epochs=70,\n",
    "              callbacks=[resnet_with_weight_decay_batch_stats, tf.keras.callbacks.LearningRateScheduler(scheduler)],\n",
    "              validation_data=(test_images, test_labels))\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,2])\n",
    "plt.plot(resnet_with_weight_decay_batch_stats.batch_losses)\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Train Accuracy\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(resnet_with_weight_decay_batch_stats.batch_acc)\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(resnet_with_weight_decay_batch_stats.epoch_val_acc)\n",
    "\n",
    "resnet_with_weight_decay_test_loss, resnet_with_weight_decay_test_acc = resnet_with_weight_decay_model.evaluate(test_images, test_labels)\n",
    "print('Resnet test accuracy : ' + str(resnet_with_weight_decay_test_acc))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1a2mPJow5bBO",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Compare Residual network and Residual network with weight decay\n",
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,2])\n",
    "plt.plot(resnet_batch_stats.batch_losses, label='resnet')\n",
    "plt.plot(resnet_with_weight_decay_batch_stats.batch_losses, label='resnet with weight decay')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Training Accuracy\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(resnet_batch_stats.batch_acc, label='resnet')\n",
    "plt.plot(resnet_with_weight_decay_batch_stats.batch_acc, label='resnet with weight decay')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(resnet_batch_stats.epoch_val_acc, label='resnet')\n",
    "plt.plot(resnet_with_weight_decay_batch_stats.epoch_val_acc, label='resnet with weight decay')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "resnet_test_loss, resnet_test_acc = resnet_model.evaluate(test_images, test_labels)\n",
    "resnet_with_weight_decay_test_loss, resnet_with_weight_decay_test_acc = resnet_with_weight_decay_model.evaluate(test_images, test_labels)\n",
    "\n",
    "print('resnet test accuracy : ' + str(resnet_test_acc))\n",
    "print('resnet with weight decay test accuracy : ' + str(resnet_with_weight_decay_test_acc))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JwddYMHLgHpe",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Residual network with dropout\n",
    "input = keras.layers.Input(shape=(32, 32, 3))\n",
    "x = keras.layers.Conv2D(32, kernel_size=3, padding='same', strides=(1, 1))(input)\n",
    "x = keras.layers.ReLU()(x)\n",
    "skip = x\n",
    "x = keras.layers.Conv2D(32, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Conv2D(32, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.Add()([x, skip])\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.MaxPool2D(2)(x)\n",
    "x = keras.layers.Conv2D(64, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "skip = x\n",
    "x = keras.layers.Conv2D(64, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Conv2D(64, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.Add()([x, skip])\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.MaxPool2D(2)(x)\n",
    "x = keras.layers.Conv2D(128, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "skip = x\n",
    "x = keras.layers.Conv2D(128, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Conv2D(128, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.Add()([x, skip])\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.AveragePooling2D(pool_size=(8, 8))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dropout(rate=0.5)(x)\n",
    "output = keras.layers.Dense(10, activation=tf.nn.softmax)(x)\n",
    "\n",
    "resnet_dropout_model = keras.models.Model(input, output)\n",
    "resnet_dropout_model.summary()\n",
    "\n",
    "resnet_dropout_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "resnet_dropout_batch_stats = CollectBatchStats()\n",
    "\n",
    "resnet_dropout_model.fit(train_images, train_labels,\n",
    "              batch_size=128,\n",
    "              epochs=70,\n",
    "              callbacks=[resnet_dropout_batch_stats, tf.keras.callbacks.LearningRateScheduler(scheduler)],\n",
    "              validation_data=(test_images, test_labels))\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,2])\n",
    "plt.plot(resnet_dropout_batch_stats.batch_losses)\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Train Accuracy\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(resnet_dropout_batch_stats.batch_acc)\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(resnet_dropout_batch_stats.epoch_val_acc)\n",
    "\n",
    "resnet_dropout_test_loss, resnet_dropout_test_acc = resnet_dropout_model.evaluate(test_images, test_labels)\n",
    "print('Resnet with dropout test accuracy : ' + str(resnet_dropout_test_acc))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FQzDiAJrZQfj",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Residual network with batch normalization\n",
    "input = keras.layers.Input(shape=(32, 32, 3))\n",
    "x = keras.layers.Conv2D(32, kernel_size=3, padding='same', strides=(1, 1))(input)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Conv2D(32, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.MaxPool2D(2)(x)\n",
    "x = keras.layers.Conv2D(64, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "skip = x\n",
    "x = keras.layers.Conv2D(64, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Conv2D(64, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Add()([x, skip])\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.MaxPool2D(2)(x)\n",
    "x = keras.layers.Conv2D(128, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "skip = x\n",
    "x = keras.layers.Conv2D(128, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Conv2D(128, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Add()([x, skip])\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.AveragePooling2D(pool_size=(8, 8))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "output = keras.layers.Dense(10, activation=tf.nn.softmax)(x)\n",
    "\n",
    "resnet_bn_model = keras.models.Model(input, output)\n",
    "resnet_bn_model.summary()\n",
    "\n",
    "resnet_bn_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "resnet_bn_batch_stats = CollectBatchStats()\n",
    "\n",
    "resnet_bn_model.fit(train_images, train_labels,\n",
    "              batch_size=128,\n",
    "              epochs=70,\n",
    "              callbacks=[resnet_bn_batch_stats, tf.keras.callbacks.LearningRateScheduler(scheduler)],\n",
    "              validation_data=(test_images, test_labels))\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,2])\n",
    "plt.plot(resnet_bn_batch_stats.batch_losses)\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Train Accuracy\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(resnet_bn_batch_stats.batch_acc)\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(resnet_bn_batch_stats.epoch_val_acc)\n",
    "\n",
    "resnet_bn_test_loss, resnet_bn_test_acc = resnet_bn_model.evaluate(test_images, test_labels)\n",
    "print('Resnet with BN test accuracy : ' + str(resnet_bn_test_acc))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DcYWLhti2FQs",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Residual network with batch normalization and weight decay\n",
    "input = keras.layers.Input(shape=(32, 32, 3))\n",
    "x = keras.layers.Conv2D(32, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(input)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "skip=x\n",
    "x = keras.layers.Conv2D(32, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Conv2D(32, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Add()([x, skip])\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.MaxPool2D(2)(x)\n",
    "\n",
    "x = keras.layers.Conv2D(64, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "skip = x\n",
    "x = keras.layers.Conv2D(64, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Conv2D(64, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Add()([x, skip])\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.MaxPool2D(2)(x)\n",
    "\n",
    "x = keras.layers.Conv2D(128, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "skip = x\n",
    "x = keras.layers.Conv2D(128, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Conv2D(128, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Add()([x, skip])\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.AveragePooling2D(pool_size=(8, 8))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "output = keras.layers.Dense(10, activation=tf.nn.softmax, kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "\n",
    "resnet_bn_wd_model = keras.models.Model(input, output)\n",
    "resnet_bn_wd_model.summary()\n",
    "\n",
    "resnet_bn_wd_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "resnet_bn_wd_batch_stats = CollectBatchStats()\n",
    "\n",
    "resnet_bn_wd_model.fit(train_images, train_labels,\n",
    "              batch_size=128,\n",
    "              epochs=70,\n",
    "              callbacks=[resnet_bn_wd_batch_stats,  tf.keras.callbacks.LearningRateScheduler(scheduler)],\n",
    "              validation_data=(test_images, test_labels))\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,2])\n",
    "plt.plot(resnet_bn_wd_batch_stats.batch_losses)\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Train Accuracy\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(resnet_bn_wd_batch_stats.batch_acc)\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(resnet_bn_wd_batch_stats.epoch_val_acc)\n",
    "\n",
    "resnet_bn_wd_test_loss, resnet_bn_wd_test_acc = resnet_bn_wd_model.evaluate(test_images, test_labels)\n",
    "print('Resnet with BN  and weight decay test accuracy : ' + str(resnet_bn_wd_test_acc))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7JbUyirrEjkI",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Compare residual network and residual network with batch normalization\n",
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,2])\n",
    "plt.plot(resnet_batch_stats.batch_losses, label='resnet')\n",
    "plt.plot(resnet_with_weight_decay_batch_stats.batch_losses, label='resnet+weight_decay')\n",
    "plt.plot(resnet_dropout_batch_stats.batch_losses, label='resnet+dropout')\n",
    "plt.plot(resnet_bn_batch_stats.batch_losses, label='resnet+bn')\n",
    "plt.plot(resnet_bn_wd_batch_stats.batch_losses, label='resnet+bn+weight_decay')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Training Accuracy\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(resnet_batch_stats.batch_acc, label='resnet')\n",
    "plt.plot(resnet_with_weight_decay_batch_stats.batch_acc, label='resnet+weight_decay')\n",
    "plt.plot(resnet_dropout_batch_stats.batch_acc, label='resnet+dropout')\n",
    "plt.plot(resnet_bn_batch_stats.batch_acc, label='resnet+bn')\n",
    "plt.plot(resnet_bn_wd_batch_stats.batch_acc, label='resnet+bn+weight_decay')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(resnet_batch_stats.epoch_val_acc, label='resnet')\n",
    "plt.plot(resnet_with_weight_decay_batch_stats.epoch_val_acc, label='resnet+weight_decay')\n",
    "plt.plot(resnet_dropout_batch_stats.epoch_val_acc, label='resnet+dropout')\n",
    "plt.plot(resnet_bn_batch_stats.epoch_val_acc, label='resnet+bn')\n",
    "plt.plot(resnet_bn_wd_batch_stats.epoch_val_acc, label='resnet+bn+weight_decay')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "resnet_test_loss, resnet_test_acc = resnet_model.evaluate(test_images, test_labels)\n",
    "resnet_with_weight_decay_test_loss, resnet_with_weight_decay_test_acc = resnet_with_weight_decay_model.evaluate(test_images, test_labels)\n",
    "resnet_dropout_test_loss, resnet_dropout_test_acc = resnet_dropout_model.evaluate(test_images, test_labels)\n",
    "resnet_bn_test_loss, resnet_bn_test_acc = resnet_bn_model.evaluate(test_images, test_labels)\n",
    "resnet_bn_wd_test_loss, resnet_bn_wd_test_acc = resnet_bn_wd_model.evaluate(test_images, test_labels)\n",
    "\n",
    "print('resnet test accuracy : ' + str(resnet_test_acc))\n",
    "print('resnet with bn test accuracy : ' + str(resnet_bn_test_acc))"
   ],
   "execution_count": 0,
   "outputs": []
  }
 ]
}