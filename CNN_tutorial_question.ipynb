{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_tutorial_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaesung93/CNN_tutorial-tensorflow-/blob/master/CNN_tutorial_question.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI4av3fij5uL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdg_sYbkkGR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load dataset\n",
        "cifar10 = keras.datasets.cifar10\n",
        "\n",
        "print(cifar10)\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "print(train_images.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_images.shape)\n",
        "print(test_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_a7kRBskXeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names =  ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer',\n",
        "               'Dog', 'Frog', 'Horse', 'Ship', 'Truck']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHj63oapkds7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cifar10 example\n",
        "plt.figure()\n",
        "plt.imshow(train_images[0])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW-yYgB3kp9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbWJ4BT8k216",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show images and labels\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[train_labels[i][0]])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XRClHKryg_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For logging\n",
        "class CollectBatchStats(tf.keras.callbacks.Callback):\n",
        "  def __init__(self):\n",
        "    self.batch_losses = []\n",
        "    self.batch_acc = []\n",
        "    self.epoch_val_acc = []\n",
        "    \n",
        "  def on_batch_end(self, batch, logs=None):\n",
        "    self.batch_losses.append(logs['loss'])\n",
        "    self.batch_acc.append(logs['accuracy'])\n",
        "   \n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    self.epoch_val_acc.append(logs['val_accucracy'])\n",
        "    \n",
        "    \n",
        "def scheduler(epoch, lr):\n",
        "  \"\"\"Helper function to retrieve the scheduled learning rate based on epoch.\"\"\"\n",
        "  if epoch == 40 or epoch ==60 : \n",
        "    lr = lr  * 0.1\n",
        "  else:\n",
        "    lr = lr\n",
        "  return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FExbAhlM7hJP",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://ibb.co/6Y82nPk\"><img src=\"https://i.ibb.co/cJwPgFj/fc.png\" alt=\"fc\" border=\"0\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQPjiUknJiKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fully connected network without ReLU\n",
        "fc_model_without_relu = keras.Sequential([\n",
        "    # Implement layers here\n",
        "])\n",
        "fc_model_without_relu.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5X4kkJ4JkAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile fully connected network without ReLU\n",
        "fc_model_without_relu.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
        "                 loss='sparse_categorical_crossentropy',\n",
        "                 metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zEluS-MJl34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train fully connected network without ReLU\n",
        "fc_without_relu_batch_stats = CollectBatchStats()\n",
        "\n",
        "fc_model_without_relu.fit(train_images, train_labels,\n",
        "             batch_size=128,\n",
        "             epochs=70,\n",
        "             callbacks=[fc_without_relu_batch_stats, tf.keras.callbacks.LearningRateScheduler(scheduler)],\n",
        "             validation_data=(test_images, test_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSdwA3UIlzuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fully connected network\n",
        "fc_model = keras.Sequential([\n",
        "    # Implement layers here\n",
        "])\n",
        "fc_model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dat9vsevVuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile fully connected network\n",
        "fc_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
        "                 loss='sparse_categorical_crossentropy',\n",
        "                 metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DluWFOUtvx40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train fully connected network\n",
        "fc_batch_stats = CollectBatchStats()\n",
        "\n",
        "fc_model.fit(train_images, train_labels,\n",
        "             batch_size=128,\n",
        "             epochs=70,\n",
        "             callbacks=[fc_batch_stats, tf.keras.callbacks.LearningRateScheduler(scheduler)],\n",
        "             validation_data=(test_images, test_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRadrwnLxk7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show train losses, train accuracy, test accuracy\n",
        "plt.figure()\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(fc_batch_stats.batch_losses)\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Training Accuracy\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(fc_batch_stats.batch_acc)\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Test Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(fc_batch_stats.epoch_val_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFg2-MrR8JrD",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://ibb.co/ZdYWYxN\"><img src=\"https://i.ibb.co/Tcbmbtr/cnn.png\" alt=\"cnn\" border=\"0\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJhV-cI4v3b3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convolutional neural network\n",
        "cnn_model = keras.Sequential([\n",
        "    #Implement CNN layers here\n",
        "])\n",
        "cnn_model.summary()\n",
        "\n",
        "# Compile CNN model\n",
        "cnn_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "cnn_batch_stats = CollectBatchStats()\n",
        "\n",
        "# Train CNN model\n",
        "cnn_model.fit(train_images, train_labels,\n",
        "              batch_size=128,\n",
        "              epochs=70,\n",
        "              callbacks=[cnn_batch_stats, tf.keras.callbacks.LearningRateScheduler(scheduler)],\n",
        "              validation_data=(test_images, test_labels))\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(cnn_batch_stats.batch_losses)\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Train Accuracy\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(cnn_batch_stats.batch_acc)\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Test Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(cnn_batch_stats.epoch_val_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T7-NC2O2n9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compare fully-connected network and CNN network\n",
        "plt.figure()\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(fc_batch_stats.batch_losses, label='fc')\n",
        "plt.plot(cnn_batch_stats.batch_losses, label='cnn')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Training Accuracy\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(fc_batch_stats.batch_acc, label='fc')\n",
        "plt.plot(cnn_batch_stats.batch_acc, label='cnn')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Test Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(fc_batch_stats.epoch_val_acc, label='fc')\n",
        "plt.plot(cnn_batch_stats.epoch_val_acc, label='cnn')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "fc_test_loss, fc_test_acc = fc_model.evaluate(test_images, test_labels)\n",
        "cnn_test_loss, cnn_test_acc = cnn_model.evaluate(test_images, test_labels)\n",
        "\n",
        "print('fc test accuracy : ' + str(fc_test_acc))\n",
        "print('cnn test accuracy : ' + str(cnn_test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDIvE3T98Tvd",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://ibb.co/3fw8kGR\"><img src=\"https://i.ibb.co/yhDMVG4/vgg.png\" alt=\"vgg\" border=\"0\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr_jUsYJAy22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VGG network\n",
        "vgg_model = keras.Sequential([\n",
        "    # Implement VGG network here\n",
        "])\n",
        "vgg_model.summary()\n",
        "\n",
        "vgg_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "vgg_batch_stats = CollectBatchStats()\n",
        "\n",
        "vgg_model.fit(train_images, train_labels,\n",
        "              batch_size=128,\n",
        "              epochs=70,\n",
        "              callbacks=[vgg_batch_stats, tf.keras.callbacks.LearningRateScheduler(scheduler)],\n",
        "              validation_data=(test_images, test_labels))\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(vgg_batch_stats.batch_losses)\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Train Accuracy\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(vgg_batch_stats.batch_acc)\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Test Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(vgg_batch_stats.epoch_val_acc)\n",
        "\n",
        "\n",
        "vgg_test_loss, vgg_test_acc = vgg_model.evaluate(test_images, test_labels)\n",
        "print('VGG test accuracy : ' + str(vgg_test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCbpCzs5Dezi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compare simple CNN network and VGG network\n",
        "plt.figure()\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(cnn_batch_stats.batch_losses, label='simple cnn')\n",
        "plt.plot(vgg_batch_stats.batch_losses, label='vgg')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Training Accuracy\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(cnn_batch_stats.batch_acc, label='simple cnn')\n",
        "plt.plot(vgg_batch_stats.batch_acc, label='vgg')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Test Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(cnn_batch_stats.epoch_val_acc, label='simple cnn')\n",
        "plt.plot(vgg_batch_stats.epoch_val_acc, label='vgg')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "cnn_test_loss, cnn_test_acc = cnn_model.evaluate(test_images, test_labels)\n",
        "vgg_test_loss, vgg_test_acc = vgg_model.evaluate(test_images, test_labels)\n",
        "\n",
        "print('simple cnn test accuracy : ' + str(cnn_test_acc))\n",
        "print('vgg test accuracy : ' + str(vgg_test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FanhtGFF8XRk",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://ibb.co/YBT4Bx3\"><img src=\"https://i.ibb.co/4RgwRH7/resnet.png\" alt=\"resnet\" border=\"0\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_UOv4dmFAgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Residual network\n",
        "\n",
        "# Implement residual network here\n",
        "\n",
        "resnet_model = keras.models.Model(input, output)\n",
        "resnet_model.summary()\n",
        "\n",
        "resnet_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "resnet_batch_stats = CollectBatchStats()\n",
        "\n",
        "resnet_model.fit(train_images, train_labels,\n",
        "              batch_size=128,\n",
        "              epochs=70,\n",
        "              callbacks=[resnet_batch_stats, tf.keras.callbacks.LearningRateScheduler(scheduler)],\n",
        "              validation_data=(test_images, test_labels))\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(resnet_batch_stats.batch_losses)\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Train Accuracy\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(resnet_batch_stats.batch_acc)\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Test Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(resnet_batch_stats.epoch_val_acc)\n",
        "\n",
        "resnet_test_loss, resnet_test_acc = resnet_model.evaluate(test_images, test_labels)\n",
        "print('Resnet test accuracy : ' + str(resnet_test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeiSE5xFD37z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compare VGG network and Residual network\n",
        "plt.figure()\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(vgg_batch_stats.batch_losses, label='vgg')\n",
        "plt.plot(resnet_batch_stats.batch_losses, label='resnet')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Training Accuracy\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(vgg_batch_stats.batch_acc, label='vgg')\n",
        "plt.plot(resnet_batch_stats.batch_acc, label='resnet')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Test Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(vgg_batch_stats.epoch_val_acc, label='vgg')\n",
        "plt.plot(resnet_batch_stats.epoch_val_acc, label='resnet')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "vgg_test_loss, vgg_test_acc = vgg_model.evaluate(test_images, test_labels)\n",
        "resnet_test_loss, resnet_test_acc = resnet_model.evaluate(test_images, test_labels)\n",
        "\n",
        "print('vgg test accuracy : ' + str(vgg_test_acc))\n",
        "print('resnet test accuracy : ' + str(resnet_test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5my917H8SJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VGG network very deep\n",
        "vgg_very_deep_model = keras.Sequential([\n",
        "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same', input_shape=(32, 32, 3)),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
        "    keras.layers.ReLU(),\n",
        "    \n",
        "    keras.layers.MaxPool2D(2),\n",
        "    \n",
        "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
        "    keras.layers.ReLU(),\n",
        "    \n",
        "    keras.layers.MaxPool2D(2),\n",
        "    \n",
        "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'),\n",
        "    keras.layers.ReLU(),\n",
        "\n",
        "    keras.layers.AveragePooling2D(pool_size=(8, 8)),\n",
        "\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "vgg_very_deep_model.summary()\n",
        "\n",
        "vgg_very_deep_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "vgg_very_deep_batch_stats = CollectBatchStats()\n",
        "\n",
        "vgg_very_deep_model.fit(train_images, train_labels,\n",
        "              batch_size=128,\n",
        "              epochs=70,\n",
        "              callbacks=[vgg_very_deep_batch_stats, tf.keras.callbacks.LearningRateScheduler(scheduler)],\n",
        "              validation_data=(test_images, test_labels))\n",
        "\n",
        "# Residual network very deep\n",
        "input = keras.layers.Input(shape=(32, 32, 3))\n",
        "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(input)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "skip = x\n",
        "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.Add()([x, skip])\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "skip = x\n",
        "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.Add()([x, skip])\n",
        "x = keras.layers.ReLU()(x)\n",
        "\n",
        "x = keras.layers.MaxPool2D(2)(x)\n",
        "\n",
        "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "skip = x\n",
        "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.Add()([x, skip])\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "skip = x\n",
        "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.Add()([x, skip])\n",
        "x = keras.layers.ReLU()(x)\n",
        "\n",
        "x = keras.layers.MaxPool2D(2)(x)\n",
        "\n",
        "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "skip = x\n",
        "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.Add()([x, skip])\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "skip = x\n",
        "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.Conv2D(16, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.Add()([x, skip])\n",
        "x = keras.layers.ReLU()(x)\n",
        "\n",
        "x = keras.layers.AveragePooling2D(pool_size=(8, 8))(x)\n",
        "x = keras.layers.Flatten()(x)\n",
        "\n",
        "output = keras.layers.Dense(10, activation=tf.nn.softmax)(x)\n",
        "\n",
        "resnet_very_deep_model = keras.models.Model(input, output)\n",
        "resnet_very_deep_model.summary()\n",
        "\n",
        "resnet_very_deep_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "resnet_very_deep_batch_stats = CollectBatchStats()\n",
        "\n",
        "resnet_very_deep_model.fit(train_images, train_labels,\n",
        "              batch_size=128,\n",
        "              epochs=70,\n",
        "              callbacks=[resnet_very_deep_batch_stats, tf.keras.callbacks.LearningRateScheduler(scheduler)],\n",
        "              validation_data=(test_images, test_labels))\n",
        "\n",
        "# Compare VGG very deep network and Residual very deep network\n",
        "plt.figure()\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(vgg_very_deep_batch_stats.batch_losses, label='vgg')\n",
        "plt.plot(resnet_very_deep_batch_stats.batch_losses, label='resnet')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Training Accuracy\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(vgg_very_deep_batch_stats.batch_acc, label='vgg')\n",
        "plt.plot(resnet_very_deep_batch_stats.batch_acc, label='resnet')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Test Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(vgg_very_deep_batch_stats.epoch_val_acc, label='vgg')\n",
        "plt.plot(resnet_very_deep_batch_stats.epoch_val_acc, label='resnet')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "vgg_very_deep_test_loss, vgg_very_deep_test_acc = vgg_very_deep_model.evaluate(test_images, test_labels)\n",
        "resnet_very_deep_test_loss, resnet_very_deep_test_acc = resnet_very_deep_model.evaluate(test_images, test_labels)\n",
        "\n",
        "print('vgg very deep test accuracy : ' + str(vgg_very_deep_test_acc))\n",
        "print('resnet very deep test accuracy : ' + str(resnet_very_deep_test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CizGpPUUximg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Residual network with weight decay\n",
        "input = keras.layers.Input(shape=(32, 32, 3))\n",
        "x = keras.layers.Conv2D(32, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(input)\n",
        "x = keras.layers.ReLU()(x)\n",
        "skip=x\n",
        "x = keras.layers.Conv2D(32, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.Conv2D(32, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "x = keras.layers.Add()([x, skip])\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.MaxPool2D(2)(x)\n",
        "x = keras.layers.Conv2D(64, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "skip = x\n",
        "x = keras.layers.Conv2D(64, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.Conv2D(64, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "x = keras.layers.Add()([x, skip])\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.MaxPool2D(2)(x)\n",
        "x = keras.layers.Conv2D(128, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "skip = x\n",
        "x = keras.layers.Conv2D(128, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.Conv2D(128, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "x = keras.layers.Add()([x, skip])\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.AveragePooling2D(pool_size=(8, 8))(x)\n",
        "x = keras.layers.Flatten()(x)\n",
        "output = keras.layers.Dense(10, activation=tf.nn.softmax, kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "\n",
        "resnet_with_weight_decay_model = keras.models.Model(input, output)\n",
        "resnet_with_weight_decay_model.summary()\n",
        "\n",
        "resnet_with_weight_decay_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "resnet_with_weight_decay_batch_stats = CollectBatchStats()\n",
        "\n",
        "resnet_with_weight_decay_model.fit(train_images, train_labels,\n",
        "              batch_size=128,\n",
        "              epochs=70,\n",
        "              callbacks=[resnet_with_weight_decay_batch_stats, tf.keras.callbacks.LearningRateScheduler(scheduler)],\n",
        "              validation_data=(test_images, test_labels))\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(resnet_with_weight_decay_batch_stats.batch_losses)\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Train Accuracy\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(resnet_with_weight_decay_batch_stats.batch_acc)\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Test Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(resnet_with_weight_decay_batch_stats.epoch_val_acc)\n",
        "\n",
        "resnet_with_weight_decay_test_loss, resnet_with_weight_decay_test_acc = resnet_with_weight_decay_model.evaluate(test_images, test_labels)\n",
        "print('Resnet test accuracy : ' + str(resnet_with_weight_decay_test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a2mPJow5bBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compare Residual network and Residual network with weight decay\n",
        "plt.figure()\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(resnet_batch_stats.batch_losses, label='resnet')\n",
        "plt.plot(resnet_with_weight_decay_batch_stats.batch_losses, label='resnet with weight decay')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Training Accuracy\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(resnet_batch_stats.batch_acc, label='resnet')\n",
        "plt.plot(resnet_with_weight_decay_batch_stats.batch_acc, label='resnet with weight decay')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Test Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(resnet_batch_stats.epoch_val_acc, label='resnet')\n",
        "plt.plot(resnet_with_weight_decay_batch_stats.epoch_val_acc, label='resnet with weight decay')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "resnet_test_loss, resnet_test_acc = resnet_model.evaluate(test_images, test_labels)\n",
        "resnet_with_weight_decay_test_loss, resnet_with_weight_decay_test_acc = resnet_with_weight_decay_model.evaluate(test_images, test_labels)\n",
        "\n",
        "print('resnet test accuracy : ' + str(resnet_test_acc))\n",
        "print('resnet with weight decay test accuracy : ' + str(resnet_with_weight_decay_test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwddYMHLgHpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Residual network with dropout\n",
        "input = keras.layers.Input(shape=(32, 32, 3))\n",
        "x = keras.layers.Conv2D(32, kernel_size=3, padding='same', strides=(1, 1))(input)\n",
        "x = keras.layers.ReLU()(x)\n",
        "skip = x\n",
        "x = keras.layers.Conv2D(32, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.Conv2D(32, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.Add()([x, skip])\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.MaxPool2D(2)(x)\n",
        "x = keras.layers.Conv2D(64, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "skip = x\n",
        "x = keras.layers.Conv2D(64, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.Conv2D(64, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.Add()([x, skip])\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.MaxPool2D(2)(x)\n",
        "x = keras.layers.Conv2D(128, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "skip = x\n",
        "x = keras.layers.Conv2D(128, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.Conv2D(128, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.Add()([x, skip])\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.AveragePooling2D(pool_size=(8, 8))(x)\n",
        "x = keras.layers.Flatten()(x)\n",
        "x = keras.layers.Dropout(rate=0.5)(x)\n",
        "output = keras.layers.Dense(10, activation=tf.nn.softmax)(x)\n",
        "\n",
        "resnet_dropout_model = keras.models.Model(input, output)\n",
        "resnet_dropout_model.summary()\n",
        "\n",
        "resnet_dropout_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "resnet_dropout_batch_stats = CollectBatchStats()\n",
        "\n",
        "resnet_dropout_model.fit(train_images, train_labels,\n",
        "              batch_size=128,\n",
        "              epochs=70,\n",
        "              callbacks=[resnet_dropout_batch_stats, tf.keras.callbacks.LearningRateScheduler(scheduler)],\n",
        "              validation_data=(test_images, test_labels))\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(resnet_dropout_batch_stats.batch_losses)\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Train Accuracy\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(resnet_dropout_batch_stats.batch_acc)\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Test Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(resnet_dropout_batch_stats.epoch_val_acc)\n",
        "\n",
        "resnet_dropout_test_loss, resnet_dropout_test_acc = resnet_dropout_model.evaluate(test_images, test_labels)\n",
        "print('Resnet with dropout test accuracy : ' + str(resnet_dropout_test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQzDiAJrZQfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Residual network with batch normalization\n",
        "input = keras.layers.Input(shape=(32, 32, 3))\n",
        "x = keras.layers.Conv2D(32, kernel_size=3, padding='same', strides=(1, 1))(input)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.Conv2D(32, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.MaxPool2D(2)(x)\n",
        "x = keras.layers.Conv2D(64, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "skip = x\n",
        "x = keras.layers.Conv2D(64, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.Conv2D(64, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.Add()([x, skip])\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.MaxPool2D(2)(x)\n",
        "x = keras.layers.Conv2D(128, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "skip = x\n",
        "x = keras.layers.Conv2D(128, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.Conv2D(128, kernel_size=3, padding='same', strides=(1, 1))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.Add()([x, skip])\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.AveragePooling2D(pool_size=(8, 8))(x)\n",
        "x = keras.layers.Flatten()(x)\n",
        "output = keras.layers.Dense(10, activation=tf.nn.softmax)(x)\n",
        "\n",
        "resnet_bn_model = keras.models.Model(input, output)\n",
        "resnet_bn_model.summary()\n",
        "\n",
        "resnet_bn_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "resnet_bn_batch_stats = CollectBatchStats()\n",
        "\n",
        "resnet_bn_model.fit(train_images, train_labels,\n",
        "              batch_size=128,\n",
        "              epochs=70,\n",
        "              callbacks=[resnet_bn_batch_stats, tf.keras.callbacks.LearningRateScheduler(scheduler)],\n",
        "              validation_data=(test_images, test_labels))\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(resnet_bn_batch_stats.batch_losses)\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Train Accuracy\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(resnet_bn_batch_stats.batch_acc)\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Test Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(resnet_bn_batch_stats.epoch_val_acc)\n",
        "\n",
        "resnet_bn_test_loss, resnet_bn_test_acc = resnet_bn_model.evaluate(test_images, test_labels)\n",
        "print('Resnet with BN test accuracy : ' + str(resnet_bn_test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcYWLhti2FQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Residual network with batch normalization and weight decay\n",
        "input = keras.layers.Input(shape=(32, 32, 3))\n",
        "x = keras.layers.Conv2D(32, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(input)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "skip=x\n",
        "x = keras.layers.Conv2D(32, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.Conv2D(32, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.Add()([x, skip])\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.MaxPool2D(2)(x)\n",
        "\n",
        "x = keras.layers.Conv2D(64, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "skip = x\n",
        "x = keras.layers.Conv2D(64, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.Conv2D(64, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.Add()([x, skip])\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.MaxPool2D(2)(x)\n",
        "\n",
        "x = keras.layers.Conv2D(128, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "skip = x\n",
        "x = keras.layers.Conv2D(128, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.Conv2D(128, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.Add()([x, skip])\n",
        "x = keras.layers.ReLU()(x)\n",
        "x = keras.layers.AveragePooling2D(pool_size=(8, 8))(x)\n",
        "x = keras.layers.Flatten()(x)\n",
        "output = keras.layers.Dense(10, activation=tf.nn.softmax, kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "\n",
        "resnet_bn_wd_model = keras.models.Model(input, output)\n",
        "resnet_bn_wd_model.summary()\n",
        "\n",
        "resnet_bn_wd_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "resnet_bn_wd_batch_stats = CollectBatchStats()\n",
        "\n",
        "resnet_bn_wd_model.fit(train_images, train_labels,\n",
        "              batch_size=128,\n",
        "              epochs=70,\n",
        "              callbacks=[resnet_bn_wd_batch_stats,  tf.keras.callbacks.LearningRateScheduler(scheduler)],\n",
        "              validation_data=(test_images, test_labels))\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(resnet_bn_wd_batch_stats.batch_losses)\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Train Accuracy\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(resnet_bn_wd_batch_stats.batch_acc)\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Test Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(resnet_bn_wd_batch_stats.epoch_val_acc)\n",
        "\n",
        "resnet_bn_wd_test_loss, resnet_bn_wd_test_acc = resnet_bn_wd_model.evaluate(test_images, test_labels)\n",
        "print('Resnet with BN  and weight decay test accuracy : ' + str(resnet_bn_wd_test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JbUyirrEjkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compare residual network and residual network with batch normalization\n",
        "plt.figure()\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(resnet_batch_stats.batch_losses, label='resnet')\n",
        "plt.plot(resnet_with_weight_decay_batch_stats.batch_losses, label='resnet+weight_decay')\n",
        "plt.plot(resnet_dropout_batch_stats.batch_losses, label='resnet+dropout')\n",
        "plt.plot(resnet_bn_batch_stats.batch_losses, label='resnet+bn')\n",
        "plt.plot(resnet_bn_wd_batch_stats.batch_losses, label='resnet+bn+weight_decay')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Training Accuracy\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(resnet_batch_stats.batch_acc, label='resnet')\n",
        "plt.plot(resnet_with_weight_decay_batch_stats.batch_acc, label='resnet+weight_decay')\n",
        "plt.plot(resnet_dropout_batch_stats.batch_acc, label='resnet+dropout')\n",
        "plt.plot(resnet_bn_batch_stats.batch_acc, label='resnet+bn')\n",
        "plt.plot(resnet_bn_wd_batch_stats.batch_acc, label='resnet+bn+weight_decay')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Test Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(resnet_batch_stats.epoch_val_acc, label='resnet')\n",
        "plt.plot(resnet_with_weight_decay_batch_stats.epoch_val_acc, label='resnet+weight_decay')\n",
        "plt.plot(resnet_dropout_batch_stats.epoch_val_acc, label='resnet+dropout')\n",
        "plt.plot(resnet_bn_batch_stats.epoch_val_acc, label='resnet+bn')\n",
        "plt.plot(resnet_bn_wd_batch_stats.epoch_val_acc, label='resnet+bn+weight_decay')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "resnet_test_loss, resnet_test_acc = resnet_model.evaluate(test_images, test_labels)\n",
        "resnet_with_weight_decay_test_loss, resnet_with_weight_decay_test_acc = resnet_with_weight_decay_model.evaluate(test_images, test_labels)\n",
        "resnet_dropout_test_loss, resnet_dropout_test_acc = resnet_dropout_model.evaluate(test_images, test_labels)\n",
        "resnet_bn_test_loss, resnet_bn_test_acc = resnet_bn_model.evaluate(test_images, test_labels)\n",
        "resnet_bn_wd_test_loss, resnet_bn_wd_test_acc = resnet_bn_wd_model.evaluate(test_images, test_labels)\n",
        "\n",
        "print('resnet test accuracy : ' + str(resnet_test_acc))\n",
        "print('resnet with bn test accuracy : ' + str(resnet_bn_test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}